{
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
      "from sklearn.tree import DecisionTreeRegressor\n",
      "from sklearn import datasets\n",
      "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
      "from sklearn.utils import shuffle\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def plot_feature_importances(feature_importances, title, feature_names):\n",
      "    # Normalize the importance values \n",
      "    feature_importances = 100.0 * (feature_importances / max(feature_importances))\n",
      "\n",
      "    # Sort the values and flip them\n",
      "    index_sorted = np.flipud(np.argsort(feature_importances))\n",
      "\n",
      "    # Arrange the X ticks\n",
      "    pos = np.arange(index_sorted.shape[0]) + 0.5\n",
      "\n",
      "    # Plot the bar graph\n",
      "    plt.figure()\n",
      "    plt.bar(pos, feature_importances[index_sorted], align='center')\n",
      "    plt.xticks(pos, feature_names[index_sorted])\n",
      "    plt.ylabel('Relative Importance')\n",
      "    plt.title(title)\n",
      "    plt.show()\n",
      "\n",
      "if __name__=='__main__':\n",
      "    # Load housing data\n",
      "    housing_data = datasets.load_boston() \n",
      "\n",
      "    # Shuffle the data\n",
      "    X, y = shuffle(housing_data.data, housing_data.target, random_state=7)\n",
      "\n",
      "    # Split the data 80/20 (80% for training, 20% for testing)\n",
      "    num_training = int(0.8 * len(X))\n",
      "    X_train, y_train = X[:num_training], y[:num_training]\n",
      "    X_test, y_test = X[num_training:], y[num_training:]\n",
      "\n",
      "    # Fit decision tree regression model\n",
      "    dt_regressor = DecisionTreeRegressor(max_depth=4)\n",
      "    dt_regressor.fit(X_train, y_train)\n",
      "\n",
      "    # Fit decision tree regression model with AdaBoost\n",
      "    ab_regressor = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=400, random_state=7)\n",
      "    ab_regressor.fit(X_train, y_train)\n",
      "\n",
      "    # Evaluate performance of Decision Tree regressor\n",
      "    y_pred_dt = dt_regressor.predict(X_test)\n",
      "    mse = mean_squared_error(y_test, y_pred_dt)\n",
      "    evs = explained_variance_score(y_test, y_pred_dt) \n",
      "    print(\"\\n#### Decision Tree performance ####\")\n",
      "    print((\"Mean squared error =\", round(mse, 2)))\n",
      "    print((\"Explained variance score =\", round(evs, 2)))\n",
      "\n",
      "    # Evaluate performance of AdaBoost\n",
      "    y_pred_ab = ab_regressor.predict(X_test)\n",
      "    mse = mean_squared_error(y_test, y_pred_ab)\n",
      "    evs = explained_variance_score(y_test, y_pred_ab) \n",
      "    print(\"\\n#### AdaBoost performance ####\")\n",
      "    print((\"Mean squared error =\", round(mse, 2)))\n",
      "    print((\"Explained variance score =\", round(evs, 2)))\n",
      "\n",
      "    # Plot relative feature importances \n",
      "    plot_feature_importances(dt_regressor.feature_importances_, \n",
      "            'Decision Tree regressor', housing_data.feature_names)\n",
      "    plot_feature_importances(ab_regressor.feature_importances_, \n",
      "            'AdaBoost regressor', housing_data.feature_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
