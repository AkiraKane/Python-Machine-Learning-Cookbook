{
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sklearn import preprocessing\n",
      "\n",
      "data = np.array([[ 3, -1.5,  2, -5.4],\n",
      "                 [ 0,  4,  -0.3, 2.1],\n",
      "                 [ 1,  3.3, -1.9, -4.3]])\n",
      "\n",
      "# mean removal\n",
      "data_standardized = preprocessing.scale(data)\n",
      "print((\"\\nMean =\", data_standardized.mean(axis=0)))\n",
      "print((\"Std deviation =\", data_standardized.std(axis=0)))\n",
      "\n",
      "# min max scaling\n",
      "data_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
      "data_scaled = data_scaler.fit_transform(data)\n",
      "print((\"\\nMin max scaled data:\\n\", data_scaled))\n",
      "\n",
      "# normalization\n",
      "data_normalized = preprocessing.normalize(data, norm='l1')\n",
      "print((\"\\nL1 normalized data:\\n\", data_normalized))\n",
      "\n",
      "# binarization\n",
      "data_binarized = preprocessing.Binarizer(threshold=1.4).transform(data)\n",
      "print((\"\\nBinarized data:\\n\", data_binarized))\n",
      "\n",
      "# one hot encoding\n",
      "encoder = preprocessing.OneHotEncoder()\n",
      "encoder.fit([[0, 2, 1, 12], [1, 3, 5, 3], [2, 3, 2, 12], [1, 2, 4, 3]])\n",
      "encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()\n",
      "print((\"\\nEncoded vector:\\n\", encoded_vector))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
